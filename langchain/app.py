import streamlit as st
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableLambda, RunnableParallel

# --- 1. CONFIGURACIÃ“N VISUAL DE LA PÃGINA ---
st.set_page_config(page_title="Simulador de Entrevistas AI", page_icon="ğŸ‘”", layout="centered")

# --- 2. BARRA LATERAL (SIDEBAR) ESTÃ‰TICA ---
with st.sidebar:
    st.title("âš™ï¸ ConfiguraciÃ³n")
    st.markdown("Bienvenido al simulador. Para que el reclutador AI comience a evaluarte, necesitamos conectar tu cuenta de Google.")
    
    # Input de API Key con estilo
    api_key = st.text_input("ğŸ”‘ Ingresa tu Google API Key:", type="password", help="Consigue tu API key gratuita en Google AI Studio.")
    
    st.divider()
    
    # Un toque extra: Elegir el rol para personalizar la experiencia
    st.markdown("### ğŸ¯ Detalles de la PasantÃ­a")
    rol = st.selectbox("Â¿A quÃ© Ã¡rea estÃ¡s aplicando?", 
                       ["Desarrollo de Software", "Marketing Digital", "AnÃ¡lisis de Datos", "Finanzas", "Recursos Humanos"])
    
    st.divider()
    if st.button("ğŸ”„ Reiniciar Entrevista", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

# --- 3. PANTALLA PRINCIPAL ---
st.title("ğŸ‘” El Reclutador Implacable")
st.markdown(f"**Entrevista para PasantÃ­a en:** `{rol}`")
st.markdown("PrepÃ¡rate. Nuestro reclutador de IA detecta respuestas genÃ©ricas y clichÃ©s. Te presionarÃ¡ para que des ejemplos reales y mÃ©tricas de impacto.")
st.divider()

# Detener la app visualmente si no hay API Key
if not api_key:
    st.warning("ğŸ‘ˆ Por favor, ingresa tu API Key de Google en el menÃº lateral para iniciar la simulaciÃ³n.")
    st.stop()

# --- 4. INICIALIZACIÃ“N DE MEMORIA Y ESTADO ---
if "messages" not in st.session_state:
    st.session_state.messages = []
    # El bot da el primer paso de forma proactiva
    pregunta_inicial = f"Hola. Veo que aplicas a la pasantÃ­a de {rol}. Para empezar, hÃ¡blame de un proyecto difÃ­cil que hayas sacado adelante y quÃ© rol exacto jugaste tÃº."
    st.session_state.current_question = pregunta_inicial
    st.session_state.messages.append({"role": "assistant", "content": pregunta_inicial})

# --- 5. LÃ“GICA DE LANGCHAIN (Basada en tu ejercicio) ---
llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", google_api_key=api_key, temperature=0.6)
output_parser = StrOutputParser()

# Clasificador dinÃ¡mico
classifier_template = PromptTemplate(
    input_variables=["question", "answer"],
    template="""Eres un evaluador estricto. Analiza la respuesta a la pregunta.
    Pregunta: {question}
    Respuesta: {answer}
    Si la respuesta da ejemplos concretos, menciona tecnologÃ­as/herramientas o detalla el 'cÃ³mo', clasifÃ­cala como 'Fuerte'.
    Si la respuesta usa clichÃ©s, es muy teÃ³rica, vaga o le falta detalle, clasifÃ­cala como 'DÃ©bil'.
    Responde ÃšNICAMENTE con la palabra: Fuerte o DÃ©bil.
    ClasificaciÃ³n:"""
)
classifier_chain = classifier_template | llm | output_parser #

# Respuestas enrutadas
strong_template = PromptTemplate(
    input_variables=["answer"],
    template="""El candidato respondiÃ³: '{answer}'.
    Valida su respuesta brevemente (1 lÃ­nea) y hazle una NUEVA pregunta tÃ©cnica o de comportamiento mÃ¡s difÃ­cil sobre lo que acaba de mencionar.
    Nueva Pregunta:"""
)
strong_chain = strong_template | llm | output_parser #

weak_template = PromptTemplate(
    input_variables=["answer"],
    template="""El candidato respondiÃ³: '{answer}'.
    Dile directamente y con tono profesional por quÃ© su respuesta es insuficiente (muy general, sin ejemplos). EXÃGELE que te dÃ© un ejemplo concreto de su vida acadÃ©mica o laboral que demuestre esa habilidad.
    Tu respuesta:"""
)
weak_chain = weak_template | llm | output_parser #

# Enrutamiento dinÃ¡mico
def route(info):
    if "fuerte" in info["result"].strip().lower():
        return strong_chain
    else:
        return weak_chain

routing_chain = (
    RunnableParallel({"result": classifier_chain, "question": lambda x: x["question"], "answer": lambda x: x["answer"]}) #
    | RunnableLambda(route) #
)

# --- 6. RENDERIZADO DEL CHAT (INTERFAZ VISUAL) ---
# Mostramos el historial con avatares atractivos
for msg in st.session_state.messages:
    if msg["role"] == "assistant":
        with st.chat_message("assistant", avatar="ğŸ§‘â€ğŸ’¼"):
            st.markdown(msg["content"])
    else:
        with st.chat_message("user", avatar="ğŸ‘¤"):
            st.markdown(msg["content"])

# --- 7. CAJA DE INPUT DEL USUARIO ---
user_input = st.chat_input("Escribe tu respuesta aquÃ­ detalladamente...")

if user_input:
    # Imprimir lo que dice el usuario en pantalla
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user", avatar="ğŸ‘¤"):
        st.markdown(user_input)
    
    # El bot piensa y responde
    with st.chat_message("assistant", avatar="ğŸ§‘â€ğŸ’¼"):
        with st.spinner("Evaluando tu respuesta..."):
            
            response = routing_chain.invoke({
                "question": st.session_state.current_question,
                "answer": user_input
            }) #
            
            st.markdown(response)
            
            # Guardamos en memoria
            st.session_state.messages.append({"role": "assistant", "content": response})
            st.session_state.current_question = response